{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_dir = Path.cwd().parent / 'runs'\n",
    "assert runs_dir.exists() and runs_dir.is_dir()\n",
    "for p in runs_dir.iterdir():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "import scripts\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "def lr_schedule(current: int, last_batch: int):\n",
    "    if current < 0.1 * last_batch:\n",
    "        return 1e-2\n",
    "    elif current < 0.75 * last_batch:\n",
    "        return 1e-3\n",
    "    else:\n",
    "        return 1e-4\n",
    "\n",
    "FONT_SIZE = 22\n",
    "\n",
    "FIVE_THIRTY_EIGHT = {\n",
    "        \"Original\": \"#000000\",\n",
    "        \"SDN\": \"#30a2da\",\n",
    "        \"PABEE\": \"#fc4f30\",\n",
    "        \"ZTW\": \"#e5ae38\",\n",
    "        \"Stacking\": \"#6d904f\",\n",
    "        \"Ensembling\": \"#810f7c\",\n",
    "}\n",
    "\n",
    "\n",
    "def running_average(xs: List[float], alpha: float):\n",
    "    res = [xs[0]]\n",
    "    for i, x in enumerate(xs[1:]):\n",
    "        res.append(alpha * x + (1 - alpha) * res[-1])\n",
    "    return res\n",
    "\n",
    "def choices_to_cost(chosen_ics: Dict[int, int], total_ops: Dict[int, torch.Tensor]) -> float:\n",
    "    total_samples = 0\n",
    "    summed_cost = 0.0\n",
    "    # print(f'chosen_ics: {chosen_ics} total_ops: {total_ops}')\n",
    "    for k, v in chosen_ics.items():\n",
    "        total_samples += v\n",
    "        summed_cost += v * total_ops[k].item()\n",
    "    return summed_cost / total_samples\n",
    "\n",
    "def mark_orig_result(data: Dict, total_ops: Dict[int, torch.Tensor], ax: matplotlib.axes.SubplotBase, name: str, color):\n",
    "    ts = np.array(sorted(data.keys()))\n",
    "    assert len(ts) == 1\n",
    "    if isinstance(total_ops, np.ndarray):\n",
    "        cost = np.array([total_ops[0]])\n",
    "    elif isinstance(total_ops, dict):\n",
    "        cost = np.array([total_ops[0]])\n",
    "    else:\n",
    "        cost = np.array([total_ops])\n",
    "    ret_mean = np.array([data[t][0] for t in ts])\n",
    "    ret_std = np.array([data[t][1] for t in ts])\n",
    "    print(f'name: {name} cost: {cost} ret_mean: {ret_mean} ret_std: {ret_std}')\n",
    "    print(f'name: {name} mean cost: {cost.mean()} averaged mean return: {ret_mean.mean()} averaged std: {ret_std.mean()}')\n",
    "    ax.scatter(cost, ret_mean, marker='X', label=name, color='black', s=250, zorder=3, linewidths=0.)\n",
    "    ax.errorbar(cost, ret_mean, yerr=ret_std, ecolor=color, alpha=0.5)\n",
    "    return cost[0]\n",
    "\n",
    "def draw_time_return_for_thresholds(data: Dict, total_ops: Dict[int, torch.Tensor], ax: matplotlib.axes.SubplotBase, name: str, color):\n",
    "    alpha = 0.25\n",
    "    ts = np.array(sorted(data.keys()))\n",
    "    cost = np.array([choices_to_cost(data[t][2], total_ops) for t in ts])\n",
    "    plot_data = [(cost[i], data[t][0], data[t][1]) for i, t in enumerate(ts)]\n",
    "    plot_data = sorted(plot_data, key=lambda x: x[0])\n",
    "    cost = np.array([d[0] for d in plot_data])\n",
    "    ret_mean = [d[1] for d in plot_data]\n",
    "    ret_mean = running_average(ret_mean, alpha=alpha)\n",
    "    ret_mean = np.array(ret_mean)\n",
    "    ret_std = [d[2] for d in plot_data]\n",
    "    ret_std = running_average(ret_std, alpha=alpha)\n",
    "    ret_std = np.array(ret_std)\n",
    "    heads = [data[t][2] for t in ts]\n",
    "    print(f'name: {name} mean cost: {cost.mean()} averaged mean return: {ret_mean.mean()} averaged std: {ret_std.mean()}')\n",
    "#     ax.scatter(cost, ret_mean, label=name, color=color)\n",
    "#     ax.errorbar(cost, ret_mean, yerr=ret_std, alpha=0.5, fmt='none', ecolor=color)\n",
    "    ax.plot(cost, ret_mean, label=name, color=color)\n",
    "    ax.fill_between(cost, ret_mean - ret_std, ret_mean + ret_std, alpha=0.3, color=color)\n",
    "\n",
    "def draw_time_return_for_ics(data: List, total_ops: Dict[int, torch.Tensor], ax: matplotlib.axes.SubplotBase, name: str, color):\n",
    "    print(f'data: {data}')\n",
    "    print(f'total_ops: {total_ops}')\n",
    "    cost = np.array([total_ops[i] for i in range(len(data) - 1)])\n",
    "    ret_mean = np.array([e[0] for e in data[:-1]])\n",
    "    ret_std = np.array([e[1] for e in data[:-1]])\n",
    "    ax.scatter(cost, ret_mean, marker='X', label=f'{name} IC', color=color, s=200, zorder=3, edgecolors='black', linewidths=1)\n",
    "    ax.errorbar(cost, ret_mean, yerr=ret_std, ecolor=color, alpha=0.5, fmt='none')\n",
    "\n",
    "def y_fmt(y, pos):\n",
    "    decades = [1e9, 1e6, 1e3, 1e0, 1e-3, 1e-6, 1e-9 ]\n",
    "    suffix  = [\"G\", \"M\", \"k\", \"\" , \"m\" , \"u\", \"n\"  ]\n",
    "    if y == 0:\n",
    "        return str(0)\n",
    "    for i, d in enumerate(decades):\n",
    "        if np.abs(y) >=d:\n",
    "            val = y/float(d)\n",
    "            signf = len(str(val).split(\".\")[1])\n",
    "            if signf == 0:\n",
    "                return '{val:d} {suffix}'.format(val=int(val), suffix=suffix[i])\n",
    "            else:\n",
    "                if signf == 1:\n",
    "                    if str(val).split(\".\")[1] == \"0\":\n",
    "                       return '{val:d} {suffix}'.format(val=int(round(val)), suffix=suffix[i]) \n",
    "                tx = \"{\"+\"val:.{signf}f\".format(signf = signf) +\"} {suffix}\"\n",
    "                return tx.format(val=val, suffix=suffix[i])\n",
    "    return y\n",
    "    \n",
    "    \n",
    "def plot_time_return_tradeoff(results_dirs: List[Path], names: List[str], title: str):\n",
    "    seaborn.set_style('whitegrid')\n",
    "    current_palette = FIVE_THIRTY_EIGHT\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 9))\n",
    "    for i, r_dir in enumerate(results_dirs):\n",
    "        thresholds_results_path = r_dir / 'eval_results'\n",
    "        ic_results_path = r_dir / 'eval_ics'\n",
    "        ops_path = r_dir / 'total_ops'\n",
    "        settings_path = r_dir / 'settings'\n",
    "        threshold_data = torch.load(thresholds_results_path)\n",
    "        if ic_results_path.exists():\n",
    "            ic_data = torch.load(ic_results_path)\n",
    "        total_ops = torch.load(ops_path)\n",
    "        settings = torch.load(settings_path)\n",
    "        if isinstance(total_ops, np.float64) or len(total_ops.keys()) == 1:\n",
    "            baseline_ops = mark_orig_result(threshold_data, total_ops, ax, names[i], current_palette[names[i]])\n",
    "        else:\n",
    "            # draw_time_return_curve(threshold_data, total_ops, ax, names[i], current_palette[names[i]])\n",
    "            draw_time_return_for_thresholds(threshold_data, total_ops, ax, names[i], current_palette[names[i]])\n",
    "            if ic_results_path.exists():\n",
    "                draw_time_return_for_ics(ic_data, total_ops, ax, names[i], current_palette[names[i]])\n",
    "    env_id = settings.env_id\n",
    "    ax.legend(loc='lower right', prop={'size': FONT_SIZE - 2})\n",
    "    # ax.set_title(settings.env_id)\n",
    "    # ax.set_title(str(results_dirs[0].name), fontdict={'fontsize': FONT_SIZE + 1})\n",
    "    ax.set_title(env_id, fontdict={'fontsize': FONT_SIZE + 1})\n",
    "    ax.set_xlabel('Inference Time', fontsize=FONT_SIZE)\n",
    "    ax.set_ylabel('Return', fontsize=FONT_SIZE)\n",
    "#     ax.set_xlim(right=1.1 * baseline_ops)\n",
    "    #\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(baseline_ops / 4))\n",
    "    ax.xaxis.set_major_formatter(mpl.ticker.PercentFormatter(xmax=baseline_ops))\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(y_fmt))\n",
    "    for tick in ax.xaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(FONT_SIZE - 4) \n",
    "    for tick in ax.yaxis.get_major_ticks():\n",
    "        tick.label.set_fontsize(FONT_SIZE - 4) \n",
    "    fig.show()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "base_names = [str(p) for p in runs_dir.glob('kld_small_IC*v?#0')]\n",
    "for base_name in base_names:\n",
    "    dir_list = [runs_dir / f'{base_name}', runs_dir / f'{base_name}_stacking#0_rensb#0']\n",
    "    names = ['Original', 'ZTW']\n",
    "    print(f'base_name: {base_name}')\n",
    "    try:\n",
    "        plot_time_return_tradeoff(dir_list, names, title)\n",
    "    except:\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('MLenv')",
   "language": "python",
   "name": "python39464bitmlenvf2470bdd70e24418a8f367ccdc515c9b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
